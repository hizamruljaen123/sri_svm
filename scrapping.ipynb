{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_play_scraper import reviews, Sort\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "def extract_app_id(playstore_url):\n",
    "    \"\"\"\n",
    "    Mengekstrak ID aplikasi dari URL Google Play Store.\n",
    "    \"\"\"\n",
    "    parsed_url = urlparse(playstore_url)\n",
    "    query_params = parse_qs(parsed_url.query)\n",
    "    if \"id\" in query_params:\n",
    "        return query_params[\"id\"][0]\n",
    "    raise ValueError(\"Invalid Play Store URL. Could not find 'id' parameter.\")\n",
    "\n",
    "def scrape_reviews_from_url(playstore_url, lang='id', country='id', num_reviews=100):\n",
    "    \"\"\"\n",
    "    Melakukan scraping ulasan dari Google Play Store dengan pengecekan duplikasi.\n",
    "    Jika ada ulasan duplikat, akan dihapus dan diambil ulang hingga jumlahnya sesuai.\n",
    "    \"\"\"\n",
    "    app_id = extract_app_id(playstore_url)\n",
    "    print(f\"Scraping reviews for App ID: {app_id}\")\n",
    "    all_reviews = set()  # Menggunakan set agar hanya ulasan unik yang tersimpan\n",
    "    count = 0\n",
    "    continuation_token = None  \n",
    "\n",
    "    while count < num_reviews:\n",
    "        result, continuation_token = reviews(\n",
    "            app_id,\n",
    "            lang=lang,\n",
    "            country=country,\n",
    "            sort=Sort.NEWEST,\n",
    "            count=num_reviews - count,\n",
    "            continuation_token=continuation_token\n",
    "        )\n",
    "\n",
    "        # **Tambahkan ulasan unik ke dalam set**\n",
    "        for r in result:\n",
    "            all_reviews.add((r['userName'], r['content'], r['score']))\n",
    "\n",
    "        count = len(all_reviews)\n",
    "        if not continuation_token:  \n",
    "            break  \n",
    "\n",
    "    # **Konversi hasil unik ke DataFrame**\n",
    "    df = pd.DataFrame(list(all_reviews), columns=['user', 'komentar', 'rating'])\n",
    "\n",
    "    # **Jika jumlah ulasan setelah filtering kurang, ambil ulang secara acak**\n",
    "    while len(df) < num_reviews:\n",
    "        print(f\"Jumlah ulasan unik masih kurang ({len(df)}/{num_reviews}), mengambil ulang...\")\n",
    "        time.sleep(random.uniform(1, 3))  # Hindari pemblokiran dengan jeda acak\n",
    "        \n",
    "        result, _ = reviews(\n",
    "            app_id,\n",
    "            lang=lang,\n",
    "            country=country,\n",
    "            sort=Sort.MOST_RELEVANT,\n",
    "            count=num_reviews - len(df),\n",
    "        )\n",
    "\n",
    "        # **Tambahkan ulasan baru**\n",
    "        for r in result:\n",
    "            all_reviews.add((r['userName'], r['content'], r['score']))\n",
    "\n",
    "        df = pd.DataFrame(list(all_reviews), columns=['user', 'komentar', 'rating'])\n",
    "\n",
    "    return df\n",
    "\n",
    "def add_labels_to_reviews(df):\n",
    "    \"\"\"\n",
    "    Menambahkan label sentimen ke DataFrame ulasan berdasarkan rating.\n",
    "    \"\"\"\n",
    "    def label_rating(rating):\n",
    "        if rating in [1, 2]:\n",
    "            return 'negatif'\n",
    "        elif rating in [3, 4, 5]:\n",
    "            return 'positif'\n",
    "\n",
    "    df['label'] = df['rating'].apply(label_rating)\n",
    "    df['sentimen'] = df['label']  # Kolom 'sentimen' sama dengan 'label'\n",
    "    return df\n",
    "\n",
    "def main_data_latih(playstore_url, num_reviews, output_file):\n",
    "    \"\"\"\n",
    "    Fungsi utama untuk scraping data latih dengan penghapusan duplikasi.\n",
    "    \"\"\"\n",
    "    print(f\"Memulai scraping {num_reviews} ulasan untuk data latih dari: {playstore_url}\")\n",
    "    reviews_df = scrape_reviews_from_url(playstore_url, num_reviews=num_reviews)\n",
    "\n",
    "    # **Menambahkan label sentimen ke data latih**\n",
    "    reviews_df = add_labels_to_reviews(reviews_df)\n",
    "\n",
    "    # **Simpan data latih ke file Excel**\n",
    "    reviews_df.to_excel(output_file, index=False)\n",
    "    print(f\"Data latih disimpan di: {output_file}\")\n",
    "\n",
    "# **Contoh penggunaan**\n",
    "if __name__ == \"__main__\":\n",
    "    playstore_url = \"https://play.google.com/store/apps/details?id=premium.gotube.adblock.utube&hl=id\"\n",
    "    num_reviews = 200  # Jumlah ulasan yang diambil untuk data latih\n",
    "    output_file = \"web/static/data/gotube/data_latih.xlsx\"  # File untuk menyimpan data latih\n",
    "\n",
    "    main_data_latih(playstore_url, num_reviews, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_play_scraper import reviews, Sort\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "def extract_app_id(playstore_url):\n",
    "    \"\"\"\n",
    "    Mengekstrak ID aplikasi dari URL Google Play Store.\n",
    "    \"\"\"\n",
    "    parsed_url = urlparse(playstore_url)\n",
    "    query_params = parse_qs(parsed_url.query)\n",
    "    if \"id\" in query_params:\n",
    "        return query_params[\"id\"][0]\n",
    "    raise ValueError(\"Invalid Play Store URL. Could not find 'id' parameter.\")\n",
    "\n",
    "def scrape_reviews_from_url(playstore_url, lang='id', country='id', num_reviews=100, offset=0):\n",
    "    \"\"\"\n",
    "    Melakukan scraping ulasan dari Google Play Store dengan offset tertentu.\n",
    "    Jika ada duplikat, ulasan akan diambil ulang hingga jumlahnya sesuai.\n",
    "    \"\"\"\n",
    "    app_id = extract_app_id(playstore_url)\n",
    "    print(f\"Scraping reviews for App ID: {app_id}\")\n",
    "    all_reviews = set()  # Menggunakan set untuk menghindari duplikasi\n",
    "    count = 0\n",
    "    continuation_token = None  \n",
    "\n",
    "    # **Skip ulasan sebanyak offset agar data uji tidak sama dengan data latih**\n",
    "    while count < offset:\n",
    "        result, continuation_token = reviews(\n",
    "            app_id,\n",
    "            lang=lang,\n",
    "            country=country,\n",
    "            sort=Sort.NEWEST,  \n",
    "            count=offset - count,  \n",
    "            continuation_token=continuation_token\n",
    "        )\n",
    "        count += len(result)\n",
    "        if not continuation_token:  \n",
    "            break  \n",
    "\n",
    "    # **Mengambil ulasan unik setelah offset**\n",
    "    count = 0\n",
    "    while count < num_reviews:\n",
    "        result, continuation_token = reviews(\n",
    "            app_id,\n",
    "            lang=lang,\n",
    "            country=country,\n",
    "            sort=Sort.NEWEST,  \n",
    "            count=num_reviews - count,  \n",
    "            continuation_token=continuation_token\n",
    "        )\n",
    "        \n",
    "        # **Tambahkan ulasan unik ke dalam set**\n",
    "        for r in result:\n",
    "            all_reviews.add((r['userName'], r['content'], r['score']))\n",
    "\n",
    "        count = len(all_reviews)  \n",
    "        if not continuation_token:  \n",
    "            break  \n",
    "\n",
    "    # **Mengubah hasil menjadi DataFrame**\n",
    "    df = pd.DataFrame(list(all_reviews), columns=['user', 'komentar', 'rating'])\n",
    "\n",
    "    # **Jika jumlah ulasan setelah filtering kurang, ambil ulang secara acak**\n",
    "    while len(df) < num_reviews:\n",
    "        print(f\"Jumlah ulasan unik masih kurang ({len(df)}/{num_reviews}), mengambil ulang...\")\n",
    "        time.sleep(random.uniform(1, 3))  # Hindari ban dengan jeda acak\n",
    "        \n",
    "        result, _ = reviews(\n",
    "            app_id,\n",
    "            lang=lang,\n",
    "            country=country,\n",
    "            sort=Sort.NEWEST,\n",
    "            count=num_reviews - len(df),\n",
    "        )\n",
    "\n",
    "        # **Tambahkan ulasan baru**\n",
    "        for r in result:\n",
    "            all_reviews.add((r['userName'], r['content'], r['score']))\n",
    "\n",
    "        df = pd.DataFrame(list(all_reviews), columns=['user', 'komentar', 'rating'])\n",
    "\n",
    "    return df\n",
    "\n",
    "def main_data_uji(playstore_url, num_reviews, offset, output_file):\n",
    "    \"\"\"\n",
    "    Fungsi utama untuk scraping data uji dengan offset agar tidak sama dengan data latih.\n",
    "    \"\"\"\n",
    "    print(f\"Memulai scraping {num_reviews} ulasan untuk data uji dari: {playstore_url}\")\n",
    "    reviews_df = scrape_reviews_from_url(playstore_url, num_reviews=num_reviews, offset=offset)\n",
    "\n",
    "    # **Simpan data uji ke file Excel**\n",
    "    reviews_df.to_excel(output_file, index=False)\n",
    "    print(f\"Data uji disimpan di: {output_file}\")\n",
    "\n",
    "# **Contoh penggunaan**\n",
    "if __name__ == \"__main__\":\n",
    "    playstore_url = \"https://play.google.com/store/apps/details?id=premium.gotube.adblock.utube&hl=id\"\n",
    "    num_reviews = 50  \n",
    "    offset = 200  \n",
    "    output_file = \"web/static/data/gotube/data_uji_test.xlsx\"  \n",
    "\n",
    "    main_data_uji(playstore_url, num_reviews, offset, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
